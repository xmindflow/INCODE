{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from scipy import io\n",
    "from tqdm.notebook import tqdm\n",
    "import io\n",
    "from IPython.display import Audio\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "from modules import utils\n",
    "from modules.models import INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='INCODE')\n",
    "\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='./incode_data/Audio/gt_bach.wav', help='Input image path')\n",
    "parser.add_argument('--inr_model',type=str, default='incode', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode]')\n",
    "parser.add_argument('--lr',type=float, default=9e-5, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.2, help='Learning rate scheduler')\n",
    "parser.add_argument('--maxpoints', type=int, default=256*256, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=1001, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=100, help='Number of steps till summary visualization')\n",
    "\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268067e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d16c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = utils.AudioFile(args.input)\n",
    "dataloader = DataLoader(audio, shuffle=True, batch_size=1, pin_memory=True, num_workers=0)\n",
    "rate, coords, ground_truth = next(iter(dataloader))\n",
    "\n",
    "coords = coords.to(device)\n",
    "gt = ground_truth.to(device)\n",
    "rate = rate[0].item()\n",
    "\n",
    "Audio(ground_truth.squeeze().numpy(), rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2563",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c717b7",
   "metadata": {},
   "source": [
    "### Defining desired Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input': len(audio.data)}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1145d",
   "metadata": {},
   "source": [
    "### Model Configureations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef27973",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Harmonizer Configurations\n",
    "MLP_configs={'task': 'audio',\n",
    "             'in_channels': 50,             \n",
    "             'hidden_channels': [50, 32, 4],\n",
    "             'mlp_bias':0.3120,\n",
    "             'activation_layer': nn.SiLU,\n",
    "             'sample_rate': rate,\n",
    "             'GT': gt.squeeze(-1)\n",
    "            }\n",
    "\n",
    "### Model Configurations\n",
    "model = INR(args.inr_model).run(in_features=1,\n",
    "                                out_features=1, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=3000.0,\n",
    "                                hidden_omega_0=30.0,\n",
    "                                pos_encode_configs=pos_encode_no, \n",
    "                                MLP_configs = MLP_configs\n",
    "                               ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db268c3d",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "psnr_values = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59bf76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for step in tqdm(range(args.niters)):\n",
    "    \n",
    "    # Calculate model output\n",
    "    if args.inr_model == 'incode':\n",
    "        model_output, coef = model(coords)  \n",
    "    else:\n",
    "        model_output = model(coords) \n",
    "    \n",
    "    # Calculate the output loss\n",
    "    output_loss = ((model_output - gt)**2).mean()\n",
    "    \n",
    "    if args.inr_model == 'incode':\n",
    "        # Calculate regularization loss for 'incode' model\n",
    "        a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "        reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                   args.b_coef * torch.relu(-b_coef) + \\\n",
    "                   args.c_coef * torch.relu(-c_coef) + \\\n",
    "                   args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "        # Total loss for 'incode' model\n",
    "        loss = output_loss + reg_loss \n",
    "    else: \n",
    "        # Total loss for other models\n",
    "        loss = output_loss\n",
    "            \n",
    "    # Perform backpropagation and update model parameters\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((model_output - gt)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values.append(psnr.item())\n",
    "    \n",
    "    # Display GT, Reconstructed audio, and Error\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.6f} | PSNR: {:.4f}\".format(step, loss.item(), psnr.item()))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 3))\n",
    "        axes[0].plot(coords.squeeze().detach().cpu().numpy(), gt.squeeze().detach().cpu().numpy())\n",
    "        axes[0].set_ylim(-1, 1)\n",
    "        axes[0].set_title('Ground Truth')\n",
    "        axes[1].plot(coords.squeeze().detach().cpu().numpy(), model_output.squeeze().detach().cpu().numpy())\n",
    "        axes[1].set_ylim(-1, 1)\n",
    "        axes[1].set_title('Reconstructed')\n",
    "        axes[2].plot(coords.squeeze().detach().cpu().numpy(), (model_output - gt).squeeze().detach().cpu().numpy())\n",
    "        axes[2].set_ylim(-0.6, 0.6)\n",
    "        axes[2].set_title('Error')\n",
    "        plt.show()\n",
    "\n",
    "    # Check if the current iteration's loss is the best so far        \n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_audio = model_output.squeeze().detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(best_audio, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4b9e",
   "metadata": {},
   "source": [
    "# Convergance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'font': 'Times New Roman', 'size': 12}\n",
    "\n",
    "plt.figure()\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 10}\n",
    "plt.rc('font', **axfont)\n",
    "\n",
    "plt.plot(np.arange(len(psnr_values[:-1])), psnr_values[:-1], label = f\"{(args.inr_model).upper()}\")\n",
    "plt.xlabel('# Epochs', fontdict=font)\n",
    "plt.ylabel('PSNR (dB)', fontdict=font)\n",
    "plt.title('Audio Representation', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "plt.legend()\n",
    "plt.grid(True, color='lightgray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
